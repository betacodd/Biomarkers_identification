{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f0d3a8d",
   "metadata": {},
   "source": [
    "# Bioinfo Project 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001eec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#includes\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import statistics\n",
    "import glob\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import umap\n",
    "\n",
    "\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fdeea",
   "metadata": {},
   "source": [
    "# Step 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d5dac",
   "metadata": {},
   "source": [
    "## Gather RNA counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eba12ea4",
   "metadata": {},
   "source": [
    "To analyze the samples, you will need to merge them into a single Python object. One standard way to do this is to build a dataframe (or any \"table like\" struture) such as each row is \"sample\" and each column is a \"gene\". Make sure to test your dataset, so that if you change something later on, errors can be catch easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe lines: customers, columns: genes\n",
    "class SampleMerger:\n",
    "    def __init__(self):          #constructor\n",
    "        self.sample_files = None #files names\n",
    "        self.df = None           #dataframe\n",
    "    \n",
    "    def __str__(self):           # print with str format\n",
    "        if self.df is None:\n",
    "            self.merge_samples()\n",
    "        return str(self.df)\n",
    "    \n",
    "    #Getters\n",
    "    def get_sample_files(self): \n",
    "        if self.sample_files is None:\n",
    "            self.set_sample_files()\n",
    "        return self.sample_files\n",
    "    \n",
    "    def get_df(self):            \n",
    "        if self.df is None:\n",
    "            self.merge_samples()\n",
    "        return self.df\n",
    "    \n",
    "    def get_sub_dataframe(self, columns):\n",
    "        if self.df is None:\n",
    "            self.merge_samples()\n",
    "        sub_df = self.df.loc[:, columns]\n",
    "        return sub_df \n",
    "    \n",
    "    #Setters\n",
    "    def set_sample_files(self):  #load files names\n",
    "        txt_files = []\n",
    "        folder_path = '../Data/'\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                txt_files.append(os.path.join(folder_path, file_name))\n",
    "        self.sample_files = txt_files\n",
    "    \n",
    "    def merge_samples(self): #Create the dataframe\n",
    "        count = 0\n",
    "        i = 0\n",
    "        j = -1\n",
    "        gene_list = []\n",
    "        nb_gene_list = [ [ None for y in range( len(self.sample_files) ) ]for x in range( 28953 ) ]\n",
    "        \n",
    "        for file in self.sample_files:\n",
    "            j += 1\n",
    "            with open(file) as fasta_file:\n",
    "                for line in fasta_file:\n",
    "                    line = line.strip()\n",
    "                    if not(line.startswith(\"g\")):\n",
    "                        gene = line.split(\"\\t\")[0]\n",
    "                        nb_gene = line.split(\"\\t\")[1]\n",
    "                        if (count == 0):\n",
    "                            gene_list.append(gene)\n",
    "                        nb_gene_list[i][j] = int(nb_gene)\n",
    "                        i += 1\n",
    "            count = 1\n",
    "            i = 0\n",
    "        dictionnary = dict()\n",
    "        for i in range (0, 28953):\n",
    "            dictionnary[gene_list[i]] = nb_gene_list[i]\n",
    "        self.df = pd.DataFrame(dictionnary)\n",
    "        \n",
    "        names = []\n",
    "        for item in self.sample_files:\n",
    "            name = item.split('/')[-1].split('.')[0]\n",
    "            names.append(name)\n",
    "        self.df.index = names\n",
    "        \n",
    "    #Step 2\n",
    "    \n",
    "    #Gen part\n",
    "    \n",
    "    def get_gen_mean_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the mean for each gene as a dictionary {key: gene; value: mean}\n",
    "        \"\"\"\n",
    "        mean_dict = dict()\n",
    "        for col in self.df.columns:\n",
    "            mean_dict[col] = self.df[col].mean()\n",
    "        return mean_dict\n",
    "\n",
    "    def get_gen_median_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the median for each gene as a dictionary {key: gene; value: median}\n",
    "        \"\"\"\n",
    "        median_dict = dict()\n",
    "        for col in self.df.columns:\n",
    "            median_dict[col] = self.df[col].median()\n",
    "        return median_dict\n",
    "\n",
    "    def get_gen_stdev_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the standard deviation for each gene as a dictionary {key: gene; value: standard deviation}\n",
    "        \"\"\"\n",
    "        stdev_dict = dict()\n",
    "        for col in self.df.columns:\n",
    "            stdev_dict[col] = self.df[col].std()\n",
    "        return stdev_dict    \n",
    "    \n",
    "    def plot_gen_mean(self):\n",
    "        gene_means = dict(self.get_gen_mean_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Gene')\n",
    "        plt.ylabel('Mean')\n",
    "        plt.plot(gene_means)\n",
    "        plt.title('Mean for each gene')\n",
    "        \n",
    "    def plot_gen_median(self):\n",
    "        gene_means = dict(self.get_gen_median_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Gene')\n",
    "        plt.ylabel('Median')\n",
    "        plt.plot(gene_means)\n",
    "        plt.title('Median for each gene')\n",
    "    \n",
    "    def plot_gen_std(self):   \n",
    "        gene_means = dict(self.get_gen_stdev_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Gene')\n",
    "        plt.ylabel('Standard Deviation')\n",
    "        plt.plot(gene_means)\n",
    "        plt.title('Standard deviation for each gene')\n",
    "        \n",
    "        \n",
    "    #Sample part \n",
    "    \n",
    "    def get_sample_mean_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the mean for each sample as a dictionary {key: gene; value: mean}\n",
    "        \"\"\"\n",
    "        \n",
    "        mean_dict = dict()\n",
    "        row_means = self.df.mean(axis=1)\n",
    "        for index, value in row_means.items():\n",
    "            mean_dict[index] = value\n",
    "        return mean_dict\n",
    "        \n",
    "\n",
    "    def get_sample_median_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the median for each sample as a dictionary {key: gene; value: median}\n",
    "        \"\"\"\n",
    "        median_dict = dict()\n",
    "        row_medians = self.df.median(axis=1)\n",
    "        for index, value in row_medians.items():\n",
    "            median_dict[index] = value\n",
    "        return median_dict\n",
    "\n",
    "    def get_sample_stdev_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return the standard deviation for each sample as a dictionary {key: gene; value: standard deviation}\n",
    "        \"\"\"\n",
    "        std_dict = dict()\n",
    "        row_stds = self.df.std(axis=1)\n",
    "        for index, value in row_stds.items():\n",
    "            std_dict[index] = value\n",
    "        return std_dict \n",
    "    \n",
    "    def plot_sample_mean(self):\n",
    "        gene_means = dict(self.get_sample_mean_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Mean')\n",
    "        plt.plot(gene_means)\n",
    "        plt.title(\"Samples mean\")\n",
    "        \n",
    "    def plot_sample_median(self):\n",
    "        gene_median = dict(self.get_sample_median_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Median')\n",
    "        plt.plot(gene_median)\n",
    "        plt.title(\"Samples median\")    \n",
    "    \n",
    "    def plot_sample_std(self):   \n",
    "        gene_std = dict(self.get_gen_stdev_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Standard Deviation')\n",
    "        plt.plot(gene_std)\n",
    "        plt.title(\"Samples standard deviation\")\n",
    "        \n",
    "\n",
    "    #Variation Coefficientpart\n",
    "    \n",
    "    def get_gen_cv_dict(self):\n",
    "        \"\"\"\n",
    "        df: dataframe\n",
    "        return cv for each gene as a dictionary {key: gene; value: variation coefficient}\n",
    "        \"\"\"\n",
    "        cv_dict = dict()\n",
    "        for col in self.df.columns:\n",
    "            cv_dict[col] = self.df[col].std()//self.df[col].median()\n",
    "        return cv_dict   \n",
    "    \n",
    "    def plot_gen_cv(self):   \n",
    "        gene_cv = dict(self.get_gen_cv_dict()).values()\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.xlabel('Gene')\n",
    "        plt.ylabel('Coefficient de Variation')\n",
    "        plt.plot(gene_cv)\n",
    "    \n",
    "    def test_data(self): #tests\n",
    "        if self.df is None:\n",
    "            self.merge_samples()\n",
    "        assert self.df.isnull().sum().sum() == 0, \"There are missing values in the merged dataframe.\"\n",
    "        assert isinstance(self.df, pd.DataFrame), \"The merged object is not a dataframe.\"\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame = SampleMerger()\n",
    "Frame.set_sample_files()\n",
    "Frame.merge_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a893b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c2eaf",
   "metadata": {},
   "source": [
    "## Gather sample annotations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2f6c46",
   "metadata": {},
   "source": [
    "The sample annotations are all placed in a unique \"xml\" file. First, open the file with any text editor, and try to understand its architecture. Then, identify the information that could be relevant for your analysis.\n",
    "\n",
    "Finally, create a dataframe (or any \"table like\" structure) such as each row is a samples and each column an annotation. Make sur to test your dataset (gene counts+annotations) so that you can catch any error in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleAnnotation:\n",
    "    def __init__(self):          #constructor\n",
    "        self.df = None           #dataframe\n",
    "        \n",
    "    def get_df(self):\n",
    "        return self.df  \n",
    "    \n",
    "    def collect_annotations(self):\n",
    "        # Reading the XML file\n",
    "        url = '{http://www.ncbi.nlm.nih.gov/geo/info/MINiML}'\n",
    "        tree = ET.parse('../Data/GSE124439_family.xml')\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # List to store annotation data\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        # Loop to loop through samples and extract other annotations\n",
    "\n",
    "        for sample in root.findall(url+'Sample'):\n",
    "\n",
    "            #Sample ID retrieval\n",
    "\n",
    "            #print(sample)\n",
    "            sample_id = sample.get('iid')\n",
    "\n",
    "\n",
    "            # Recovery of annotations\n",
    "\n",
    "            annotations = {}\n",
    "            for i in sample.findall(url+'Channel'):\n",
    "                for charac in i.findall(url+'Characteristics'):\n",
    "\n",
    "\n",
    "                    if charac.get('tag') in ['cns subregion', 'subject id', 'sample group']:\n",
    "\n",
    "                        annotations[charac.get('tag')] = charac.text.strip()\n",
    "\n",
    "            # Add data to list\n",
    "\n",
    "            data = {'sample_id': sample_id, **annotations}\n",
    "            data_list.append(data)\n",
    "\n",
    "        # Creating the DataFrame from the data\n",
    "\n",
    "        self.df = pd.DataFrame(data_list)  \n",
    "    \n",
    "    def represent_sample_groups(self):\n",
    "        counts = self.df['sample group'].value_counts(normalize=True) * 100\n",
    "\n",
    "        # Créer un diagramme camembert\n",
    "        plt.pie(counts.values, labels=counts.index, autopct='%1.1f%%', colors=['red', 'blue', 'green'])\n",
    "        plt.title('Répartition des sujets par catégorie')\n",
    "        plt.show()\n",
    "\n",
    "    def represent_cns_subregion(self):\n",
    "        counts = self.df['cns subregion'].value_counts(normalize=True) * 100\n",
    "\n",
    "        # Créer un diagramme camembert\n",
    "        plt.pie(counts.values, labels=counts.index, autopct='%1.1f%%', colors=['red', 'blue', 'green', 'yellow'])\n",
    "        plt.title('Répartition des sujets par catégorie')\n",
    "        plt.show()\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.df is None:\n",
    "            self.collect_annotations()\n",
    "            \n",
    "        return str(self.df)\n",
    "    \n",
    "    def get_sub_dataframe(self, columns):\n",
    "        if self.df is None:\n",
    "            self.merge_samples()\n",
    "        sub_df = self.df.loc[:, columns]\n",
    "        return sub_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations = SampleAnnotation()\n",
    "Annotations.collect_annotations()\n",
    "Annotations.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations.represent_sample_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations.represent_cns_subregion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4a267",
   "metadata": {},
   "source": [
    "# Step 2 - Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e88e4",
   "metadata": {},
   "source": [
    "## RNA counts description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297439f",
   "metadata": {},
   "source": [
    "For each gene, compute the mean, the median and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc92e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame.plot_gen_mean()\n",
    "Frame.plot_gen_median()\n",
    "Frame.plot_gen_std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representing standard deviation according to the mean and median (for genes)\n",
    "\n",
    "gen_mean_dict = Frame.get_gen_mean_dict()\n",
    "gen_median_dict = Frame.get_gen_median_dict()\n",
    "gen_stdev_dict = Frame.get_gen_stdev_dict()\n",
    "\n",
    "plt.scatter(x = gen_mean_dict.values(), y = gen_stdev_dict.values())\n",
    "plt.title(\"Standard deviation according to the mean for each gene\")\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Standard Deviation\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x = gen_median_dict.values(), y = gen_stdev_dict.values())\n",
    "plt.title(\"Standard deviation according to the median for each gene\")\n",
    "plt.xlabel(\"Median\")\n",
    "plt.ylabel(\"Standard Deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba984c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing Variation Coefficient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a246bf26",
   "metadata": {},
   "source": [
    "## Samples description:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c735522",
   "metadata": {},
   "source": [
    "For each sample, compute the mean (across all genes), the median, the standard deviation. Find a way to efficiently report all those data. As for the RNA counts, think about which subsets you can analyse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0775227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representing standard deviation according to the mean and median (for samples)\n",
    "\n",
    "sam_mean_dict = Frame.get_sample_mean_dict()\n",
    "sam_median_dict = Frame.get_sample_median_dict()\n",
    "sam_stdev_dict = Frame.get_sample_stdev_dict()\n",
    "\n",
    "plt.scatter(x = sam_mean_dict.values(), y = sam_stdev_dict.values())\n",
    "plt.title(\"Standard deviation according to the mean for each sample\")\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Standard Deviation\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x = sam_median_dict.values(), y = sam_stdev_dict.values())\n",
    "plt.title(\"Standard deviation according to the median for each sample\")\n",
    "plt.xlabel(\"Median\")\n",
    "plt.ylabel(\"Standard Deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f655e321",
   "metadata": {},
   "source": [
    "# Step 3: PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ff265f",
   "metadata": {},
   "source": [
    "As you may have observed, the number of genes is far too high to compare all samples using all genes with simple analyses. The PCA is a classical first step analysis in those cases, and offers (among other things) a good way to visualize your data. To understand what a PCA is, let's check at my favorite youtube channel: StatQuest: PCA Step-by-Step. We will review the video together, wait for me please.\n",
    "\n",
    "To implement a PCA in python, a simple way is to use the PCA function in the sklearn.decomposition package. Scikit-learn is a wonderfull Python library, and contains a lot of \"must-have\" features needed for a data-scientist. Take some time to visite the official website. For a pratical python PCA tutorial, let's check again a Josh Starmer's video.\n",
    "\n",
    "Now, perform a PCA and plot the samples using their coordinates in the first PCs. TIPs: to select the good number of PCs, compute the percenatage of variance their capture. Use the annotations to color your plots, and see if you can already observe some kind of signal.\n",
    "\n",
    "PCA is also good way to find outliers. Outliers are samples that are greatly different from the other samples. The difference should be \"huge\", so that only experimental errors could explain it. Using the PCA and visualization, look at possible outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d403ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"m1-m2 / ecart-type\" pour bien voir la difference entre deux groupes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82b89727",
   "metadata": {},
   "source": [
    "# Step 4: tSNE and UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c158d5",
   "metadata": {},
   "source": [
    "Another (more recent) good vizualization tool for high dimensional data is the t-SNE, and it's little brother, the UMAP. The advantage of this two methods is that they can reduce the dimension of your data using a desired number of of component (2 most of the time), not leaving alway a part of your data variability (in theory). On the other hand, they do not preserve large distance interpretation, so that only \"local similarities\" must be interpreted (e.g., outliers are much more difficult to spot). UMAP tends to preserve much better large distances, but still not reach the PCA in this topic.\n",
    "\n",
    "Try to implement a t-SNE and/or a UMAP. UMAP can be implemented using the \"umap\" module, whereas t-SNE has a scikit-learn implementation.\n",
    "\n",
    "Compare this visualition vs the PCA one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Normalisation\n",
    "df_norm = (Frame.df - Frame.df.min()) / (Frame.df.max() - Frame.df.min())\n",
    "df_norm.fillna(gen_mean_dict, inplace=True)\n",
    "\n",
    "df_norm.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "340b7f97",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm[df_norm.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b056937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In research of the best hyperparams\n",
    "\n",
    "# param_grid = {'perplexity': [5, 10, 20, 30, 40],\n",
    "#               'learning_rate': [10, 50, 100, 200, 500]}\n",
    "\n",
    "# tsne = TSNE(n_components=2, verbose=1, n_iter=1000)\n",
    "# grid_search = GridSearchCV(tsne, param_grid, cv=5, scoring='f1')\n",
    "# grid_search.fit(X)\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=5, n_iter=1000, learning_rate=10)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db8a26df",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In research of the best hyperparams\n",
    "# n_neighbors = [5,10,15]\n",
    "# min_dist = [0.1,0.5,1]\n",
    "# metric = ['euclidean', 'manhattan']\n",
    "\n",
    "# for n in n_neighbors:\n",
    "#     for d in min_dist:\n",
    "#         for m in metric:\n",
    "#             print(n,d,m)\n",
    "#             umap_obj = umap.UMAP(n_neighbors=n, min_dist=d, metric=m)\n",
    "#             umap_result = umap_obj.fit_transform(X)\n",
    "#             plt.scatter(umap_result[:,0], umap_result[:,1])\n",
    "#             plt.title('UMAP Projection')\n",
    "#             plt.xlabel('UMAP 1')\n",
    "#             plt.ylabel('UMAP 2')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_obj = umap.UMAP(n_neighbors=5, min_dist=0.1, metric='euclidean')\n",
    "umap_result = umap_obj.fit_transform(X)\n",
    "plt.scatter(umap_result[:,0], umap_result[:,1])\n",
    "plt.title('UMAP Projection')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da15d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
